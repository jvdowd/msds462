{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "msds_462_module1_fashion_mnist.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPpZw6KAdOck7FxC4gnOWTH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jvdowd/msds462/blob/master/msds_462_module1_fashion_mnist.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KUTMB7bPdVP3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Update keras if needed to accomodate requirements in packages used\n",
        "# !pip install -U keras\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l2yrDvsJdZhU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "2905e21e-3472-46fd-9e67-0e9b709e58a0"
      },
      "source": [
        "# Import relevant packages and \n",
        "# TensorFlow and tf.keras\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# Import Model-Related Packages\n",
        "from keras.models import Sequential, model_from_json\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.utils import to_categorical\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "# Import sklearn tools for model selection and evaluation\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# Helper libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Show plots in the notebook\n",
        "%matplotlib inline\n",
        "\n",
        "# Check version of tensorflow\n",
        "print(tf.__version__)\n",
        "\n",
        "# Google Drive packages for saving model for future use\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive \n",
        "from google.colab import auth \n",
        "from oauth2client.client import GoogleCredentials\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.2.0-rc2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jGr-4_A2dbiv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "8af7be2b-2735-4d3e-ff4f-28f5d96914e2"
      },
      "source": [
        "# Grab data using keras API and separate into train and test data\n",
        "fashion_mnist = keras.datasets.fashion_mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
        "\n",
        "# Define input shape for use in CNN convolution layers\n",
        "img_rows, img_cols = 28, 28\n",
        "input_shape = (img_rows, img_cols, 1)\n",
        "\n",
        "# Convert labels to categorical variables for use in model\n",
        "y_train = to_categorical(train_labels)\n",
        "y_test = to_categorical(test_labels)\n",
        "\n",
        "# Check size of labels and training data\n",
        "print(train_labels.shape, y_train.shape)\n",
        "print(test_labels.shape, y_test.shape)\n",
        "\n",
        "#Here we split validation data to optimize classifier during training, using 20% of training data to optimize training\n",
        "X_train, X_val, y_train, y_val = train_test_split(train_images, y_train, test_size=0.2, random_state=573)\n",
        "\n",
        "# Define test data variables\n",
        "X_test = test_images\n",
        "y_test = y_test\n",
        "\n",
        "# Reshape training, validation and test data for use in the CNN\n",
        "X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\n",
        "X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\n",
        "X_val = X_val.reshape(X_val.shape[0], img_rows, img_cols, 1)\n",
        "\n",
        "# Set training vars to float32 in order to divide by 255, scaling pixel values to between 0 and 1\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_val = X_val.astype('float32')\n",
        "\n",
        "X_train /= 255\n",
        "X_test /= 255\n",
        "X_val /= 255"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000,) (60000, 10)\n",
            "(10000,) (10000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W76dZOgegzjt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
        "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ukjT43r2dblZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        },
        "outputId": "5090de6f-9ecd-43e6-c5d8-7ad3130caf68"
      },
      "source": [
        "# Define settings for training process\n",
        "batch_size = 256\n",
        "num_classes = 10\n",
        "epochs = 50\n",
        "\n",
        "# Define Sequential Model for CNN\n",
        "model = Sequential()\n",
        "\n",
        "# First, add a convolutional layer, pooling and dropout\n",
        "model.add(Conv2D(32, kernel_size=(3, 3),\n",
        "                 activation='relu',\n",
        "                 kernel_initializer='he_normal',\n",
        "                 input_shape=input_shape))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "# Next, add second convolutional layer, pooling and dropout\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "# Third\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "# One dense hidden layer with dropout\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "# Add output layer with appropriate number of classes and softmax activation to give a probability of each class\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer=keras.optimizers.Adam(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Summarize the CNN architecture\n",
        "model.summary()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 13, 13, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 13, 13, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 11, 11, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 5, 5, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 5, 5, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 3, 3, 128)         73856     \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 3, 3, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 1152)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 128)               147584    \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 241,546\n",
            "Trainable params: 241,546\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8YeJbsddbnz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        },
        "outputId": "07897ce0-32b8-4961-908c-098848a87ee0"
      },
      "source": [
        "%%timeit\n",
        "\n",
        "# Set callback functions to early stop training and save the best model so far\n",
        "callbacks = [EarlyStopping(monitor='val_loss', patience=2),\n",
        "             ModelCheckpoint(filepath='best_model.h5', monitor='val_loss', save_best_only=True)]\n",
        "\n",
        "# Train the model using selected parameters\n",
        "\n",
        "history = model.fit(\n",
        "                    X_train\n",
        "                    , y_train\n",
        "                    , batch_size=batch_size\n",
        "                    , epochs=epochs\n",
        "                    , verbose=1\n",
        "                    , validation_data=(X_val, y_val)\n",
        "                    , callbacks = callbacks\n",
        "                    )\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 48000 samples, validate on 12000 samples\n",
            "Epoch 1/50\n",
            "48000/48000 [==============================] - 44s 920us/step - loss: 0.8835 - accuracy: 0.6698 - val_loss: 0.5365 - val_accuracy: 0.8087\n",
            "Epoch 2/50\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py:165: UserWarning: TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
            "  'TensorFlow optimizers do not '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "48000/48000 [==============================] - 44s 912us/step - loss: 0.5246 - accuracy: 0.8046 - val_loss: 0.4021 - val_accuracy: 0.8549\n",
            "Epoch 3/50\n",
            "48000/48000 [==============================] - 44s 909us/step - loss: 0.4491 - accuracy: 0.8355 - val_loss: 0.3569 - val_accuracy: 0.8674\n",
            "Epoch 4/50\n",
            "48000/48000 [==============================] - 43s 904us/step - loss: 0.4028 - accuracy: 0.8533 - val_loss: 0.3303 - val_accuracy: 0.8753\n",
            "Epoch 5/50\n",
            "48000/48000 [==============================] - 44s 909us/step - loss: 0.3754 - accuracy: 0.8624 - val_loss: 0.3151 - val_accuracy: 0.8815\n",
            "Epoch 6/50\n",
            "48000/48000 [==============================] - 44s 907us/step - loss: 0.3482 - accuracy: 0.8718 - val_loss: 0.2904 - val_accuracy: 0.8926\n",
            "Epoch 7/50\n",
            "48000/48000 [==============================] - 44s 910us/step - loss: 0.3320 - accuracy: 0.8774 - val_loss: 0.2731 - val_accuracy: 0.9003\n",
            "Epoch 8/50\n",
            "10752/48000 [=====>........................] - ETA: 31s - loss: 0.3139 - accuracy: 0.8848"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VCMAJgR7dbqA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "score = model.evaluate(X_test, y_test, verbose=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ve0NAfj_sypL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vIN6VKLWfO45",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# get predicted classes for test data\n",
        "predicted_classes = model.predict_classes(X_test)\n",
        "\n",
        "# Create classification report for the test data\n",
        "print(classification_report(test_labels, predicted_classes, target_names=class_names))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHRx-p4Xf3iG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create confusion matrix and plot using seaborn\n",
        "cm = confusion_matrix(test_labels, predicted_classes) #, labels=class_names)\n",
        "\n",
        "f = plt.figure(figsize=(15,10))\n",
        "ax = f.add_subplot()\n",
        "sns.heatmap(cm, annot=True, ax = ax, fmt=\"d\", cmap='Blues'); #annot=True to annotate cells\n",
        "\n",
        "# labels, title and ticks\n",
        "ax.set_xlabel('Predicted labels');\n",
        "ax.set_ylabel('True labels'); \n",
        "ax.set_title('Confusion Matrix'); \n",
        "ax.xaxis.set_ticklabels(class_names); ax.yaxis.set_ticklabels(class_names);\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58oagJuUrTFw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# accuracy = history['accuracy']\n",
        "# val_accuracy = history.history['val_accuracy']\n",
        "\n",
        "# loss = history.history['loss']\n",
        "# val_loss = history.history['val_loss']\n",
        "\n",
        "# epochs = range(len(accuracy))\n",
        "\n",
        "# plt.plot(epochs, accuracy, 'bo', label='Training accuracy')\n",
        "# plt.plot(epochs, val_accuracy, 'b', label='Validation accuracy')\n",
        "# plt.title('Training and validation accuracy')\n",
        "# plt.legend()\n",
        "# plt.figure()\n",
        "# plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "# plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "# plt.title('Training and validation loss')\n",
        "# plt.legend()\n",
        "# plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RvcwFRrUt_2K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save model to Google Drive\n",
        "# auth.authenticate_user()\n",
        "# gauth = GoogleAuth()\n",
        "# gauth.credentials = GoogleCredentials.get_application_default()                       \n",
        "# drive = GoogleDrive(gauth)\n",
        "\n",
        "# # serialize model to JSON\n",
        "# model_json = model.to_json()\n",
        "# with open(\"model.json\", \"w\") as json_file:\n",
        "#     json_file.write(model_json)\n",
        "\n",
        "# model_file = drive.CreateFile({'title' : 'model.json'})                       \n",
        "# model_file.SetContentFile('model.json')                       \n",
        "# model_file.Upload()\n",
        "\n",
        "# # download to google drive                       \n",
        "# drive.CreateFile({'id': model_file.get('id')})\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FVr7jJZlyLOj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save weights to Google Drive\n",
        "# # serialize weights to HDF5\n",
        "# model.save_weights('model.h5')\n",
        "\n",
        "# model_weights = drive.CreateFile({'title' : 'model.h5'})                       \n",
        "# model_weights.SetContentFile('model.h5')                       \n",
        "# model_weights.Upload()\n",
        "\n",
        "# # download to google drive                       \n",
        "# drive.CreateFile({'id': model_weights.get('id')})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NpQSa_ImiZNy",
        "colab_type": "text"
      },
      "source": [
        "# **References**\n",
        "Some helpful resources I found when assembling and troubleshooting my code\n",
        "\n",
        "*  https://www.tensorflow.org/tutorials/keras/classification\n",
        "\n",
        "*  https://www.kaggle.com/bugraokcu/cnn-with-keras/notebook\n",
        "*  https://machinelearningmastery.com/loss-and-loss-functions-for-training-deep-learning-neural-networks/\n",
        "*  https://medium.com/technologymadeeasy/the-best-explanation-of-convolutional-neural-networks-on-the-internet-fbb8b1ad5df8\n",
        "*   https://medium.com/@amarbudhiraja/https-medium-com-amarbudhiraja-learning-less-to-learn-better-dropout-in-deep-machine-learning-74334da4bfc5\n",
        "*   https://machinelearningmastery.com/how-to-stop-training-deep-neural-networks-at-the-right-time-using-early-stopping/\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ]
}